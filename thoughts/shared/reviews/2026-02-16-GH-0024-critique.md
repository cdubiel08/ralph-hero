---
date: 2026-02-16
github_issue: 24
github_url: https://github.com/cdubiel08/ralph-hero/issues/24
plan_document: thoughts/shared/plans/2026-02-16-GH-0024-smart-duplicate-detection.md
status: approved
type: critique
---

# Plan Critique: GH-24 Smart Duplicate Detection During Triage

## Verdict: APPROVED with warnings

The plan is well-structured, technically sound, and implementable as-is. The two-phase approach (pure similarity module, then MCP tool) has clean dependency ordering. All referenced files exist, line numbers are accurate or within 1-2 lines, and the algorithm implementation is correct. The "What We're NOT Doing" section is well-scoped. Five warnings are noted below but none are blocking.

## Codebase Claim Verification

### 1. `list_issues` query filter at issue-tools.ts:528-537 -- VERIFIED

The plan references lines 528-537 for the `query` filter code. Actual location is **lines 528-537 exactly**. The code snippet in the plan matches the source verbatim:

```typescript
// Filter by search query (simple title/body substring match)
if (args.query) {
  const q = args.query.toLowerCase();
  items = items.filter((item) => {
    const content = item.content as Record<string, unknown> | null;
    const title = ((content?.title as string) || "").toLowerCase();
    const body = ((content?.body as string) || "").toLowerCase();
    return title.includes(q) || body.includes(q);
  });
}
```

Note: The plan's snippet omits the `content` cast line and the `const content` line that appear in the actual code, but the logic is accurately represented.

### 2. `resolveConfig()` at issue-tools.ts:329-344 -- VERIFIED

Function exists at **lines 329-344 exactly**. Signature matches the plan's claim: `resolveConfig(client: GitHubClient, args: { owner?: string; repo?: string }): { owner: string; repo: string }`. The pattern of using `client.config.owner` and `client.config.repo` as defaults is correct.

### 3. `toolSuccess`/`toolError` at types.ts:246-257 -- VERIFIED

`toolSuccess` is at **lines 246-250**, `toolError` is at **lines 252-257**. Both are exported functions as claimed. The plan correctly identifies them as standard response formatters.

### 4. `get_issue` tool at issue-tools.ts:585-879 -- VERIFIED

The `ralph_hero__get_issue` tool registration spans **lines 585-879 exactly**. Line 585 is the `server.tool(` comment block, line 879 closes the tool registration. The plan's claim that this tool fetches title and body is correct.

### 5. `client.query()` at github-client.ts:173-191 -- VERIFIED

The `query` method is at **lines 173-191 exactly**. Signature matches: `query<T>(queryString: string, variables?: Record<string, unknown>, options?: { cache?: boolean; cacheTtlMs?: number }): Promise<T>`. The plan can use this for the search query. The caching behavior (keyed on query string + variables) is correct.

### 6. `create_comment` ends at ~line 1465, `detect_pipeline_position` starts after -- VERIFIED

`create_comment` tool's `server.tool()` call closes at **line 1465** (the closing `);` of the tool registration). `detect_pipeline_position` comment block starts at **line 1467**, with `server.tool(` at **line 1470**. The insertion point between lines 1465 and 1467 is correct.

### 7. `lib/similarity.ts` does NOT exist -- VERIFIED

No file at `plugin/ralph-hero/mcp-server/src/lib/similarity.ts` or any worktree. Glob search returned no results. The plan correctly identifies this as a new file.

### 8. `__tests__/find-duplicates.test.ts` does NOT exist -- VERIFIED

No file at `plugin/ralph-hero/mcp-server/src/__tests__/find-duplicates.test.ts`. Glob search returned no results. New file creation is correct.

### 9. `__tests__/similarity.test.ts` does NOT exist -- VERIFIED

No file at `plugin/ralph-hero/mcp-server/src/__tests__/similarity.test.ts`. Glob search returned no results. New file creation is correct.

### 10. `@octokit/graphql` v9 reserved word note -- VERIFIED

The plan correctly notes that `@octokit/graphql` v9 reserves `query` as an option key (documented in CLAUDE.md: "Never use these as GraphQL variable names"). The plan avoids this by using `searchQuery` as the GraphQL variable name instead of `query`. This is correct and important.

### 11. GraphQL search connection syntax -- VERIFIED

The `search(query: $searchQuery, type: ISSUE, first: 50)` syntax is valid GitHub GraphQL API. The `search` connection accepts `query: String!`, `type: SearchType!`, and `first: Int`. The `... on Issue { }` inline fragment on `nodes` is the correct way to extract issue-typed results from the search union type.

### 12. File size consideration -- NOTED

`issue-tools.ts` is currently **2,027 lines**. Adding the `find_duplicates` tool (estimated ~80-100 lines of handler code) would push it to ~2,130 lines. This is addressed in Warning #3 below.

## Warnings

### 1. Dice-Sorensen Implementation Uses Sets Instead of Multisets (Correctness Issue)

The plan's `diceSorensen` implementation uses `Set<string>` for bigrams, which deduplicates repeated bigrams. The classical Dice-Sorensen coefficient uses **multisets** (bags) where duplicate bigrams count. For example, "aab" produces bigrams ["aa", "ab"] (2 unique) while "aaa" produces ["aa", "aa"] (1 unique in a Set, but 2 in a multiset).

For short issue titles, this difference is minimal and the Set-based approach is a widely-accepted simplification (used by `string-similarity-js` and most lightweight implementations). However, the plan should acknowledge this is the **set-based variant**, not the classical multiset formula.

**Impact**: Low. For typical issue titles (5-15 words, few repeated bigrams), the difference is negligible. Not a blocker.

### 2. 256-Character GitHub Search Query Limit Claim is Inaccurate

The plan and research document claim GitHub search queries are "limited to 256 characters." GitHub's official documentation does not specify a 256-character limit for search queries. The documented limits are:

- Maximum 256 characters for **individual search terms** (not the entire query)
- Query strings can be longer than 256 characters total
- Up to 5 `NOT` operators per query

The plan's `extractSearchKeywords` truncates to 200 characters "leaving room for `repo:` and `is:issue` qualifiers in the 256-char limit." This conservative truncation is fine in practice (shorter queries are better for recall), but the stated rationale is based on an inaccurate limit.

**Impact**: None on implementation. The 200-char truncation is a reasonable heuristic regardless of the exact limit.

### 3. Adding to `issue-tools.ts` (2,027 Lines) Creates Maintainability Debt

The plan adds the `find_duplicates` tool to `issue-tools.ts`, which is already the largest file in the MCP server at 2,027 lines. The file currently contains 8 tools (`list_issues`, `get_issue`, `create_issue`, `update_issue`, `update_workflow_state`, `update_estimate`, `update_priority`, `create_comment`, `detect_pipeline_position`, `check_convergence`, `pick_actionable_issue`) -- actually 11 tools.

Adding yet another tool increases the file toward 2,130 lines. The plan's rationale (consistency with other issue tools) is valid, but the file is becoming unwieldy.

**Recommendation**: Not a blocker for this PR, but the implementer should consider whether a future ticket to extract search/discovery tools into a separate `search-tools.ts` file would be warranted. The `find_duplicates` tool has a different concern (search + similarity) than CRUD operations.

### 4. Stop Words List Includes Action Verbs That May Be Meaningful

The plan's `STOP_WORDS` set includes `"add"`, `"new"`, and `"use"`, which are common in issue titles. Examples:

- "Add batch operations" -- "add" is a stop word, leaving "batch operations"
- "New dashboard view" -- "new" is a stop word, leaving "dashboard view"

These removals are generally correct for search keyword extraction (GitHub search doesn't weight these verbs). However, `"add"` and `"new"` could distinguish between "Add X" (feature request) and "Fix X" (bug fix) if both exist. Since the plan uses title **similarity scoring** as the second phase (not just search), this is mitigated.

**Impact**: Low. The stop word list is reasonable for keyword extraction. Edge cases would be caught by the similarity scoring phase.

### 5. `first: 50` on Search Results May Miss Duplicates

The plan uses `first: 50` on the GitHub search query. For repos with many issues containing similar keywords, the most relevant duplicates might not appear in the first 50 results. GitHub search does not guarantee relevance ordering (results are ordered by "best match" which is opaque).

For the target use case (repos with <500 issues), 50 candidates is almost certainly sufficient. For larger repos, this could be a limitation.

**Recommendation**: Consider adding a note that pagination support could be added later, or increase to `first: 100` (still within API limits and minimal cost increase).

## What's Good

- **Clean two-phase architecture**: Pure `lib/similarity.ts` (zero API deps, fully unit-testable) separated from the MCP tool handler. This follows the existing codebase pattern (`lib/group-detection.ts`, `lib/pipeline-detection.ts`).
- **No new dependencies**: DIY Dice-Sorensen is ~15 lines. The server stays at 4 production dependencies.
- **Correct avoidance of `@octokit/graphql` v9 reserved words**: Using `searchQuery` instead of `query` as the GraphQL variable name.
- **Transparent debugging**: Including `searchQuery` in the response lets the triage agent see exactly what was searched.
- **Appropriate scope boundaries**: "Not auto-closing duplicates," "not updating the triage skill" -- these are correctly deferred to follow-up work.
- **Good test strategy**: Pure function testing for similarity (no mocking), extracted `scoreCandidates()` helper for tool logic testing.
- **Correct use of existing patterns**: `resolveConfig()`, `toolSuccess`/`toolError`, `client.query()` -- all match established patterns.
- **Reasonable defaults**: 0.3 threshold (conservative, avoids false negatives), 10 max candidates, open issues only by default.
- **API cost analysis**: 4-6 points per call is negligible against the 5000/hour budget. Correctly notes the separate 30 req/min search rate limit.

## Algorithm Assessment

The Dice-Sorensen bigram coefficient is appropriate for issue title comparison:
- Short string optimized (titles are typically 5-15 words)
- Fast: O(n) bigram extraction, O(n) intersection
- No dependencies or training data needed
- Well-understood behavior: high scores for similar phrasing, low for different concepts

The two-phase approach (keyword retrieval then local scoring) correctly avoids O(n^2) comparison and leverages GitHub's search infrastructure for candidate narrowing.

**Known limitation** (correctly acknowledged in the plan): Keyword-based retrieval will miss semantic duplicates with completely different wording. This is acceptable for an MVP and is mitigated by the triage agent's own reasoning capabilities.

## Summary

The plan is ready for implementation. The core design (similarity module + MCP tool, two-phase retrieval + scoring) is sound, well-specified, and follows established codebase patterns. All line number references are accurate. The five warnings are informational -- none require plan revision. An implementer should be aware of the Set-based bigram simplification (Warning #1) and the growing size of `issue-tools.ts` (Warning #3), but neither blocks implementation.
